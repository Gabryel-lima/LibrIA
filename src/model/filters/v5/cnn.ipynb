{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision mediapipe scikit-learn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CNN com Suavização Temporal e Exportação JIT — Versão Otimizada\n",
    "# Este notebook ajustado visa reduzir gargalos de I/O e CPU/GPU, implementar Inferência com Suavização Temporal e acelerar a exportação JIT.\n",
    "    \n",
    "# 1. Importações e Configurações\n",
    "import os, random, string\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Acelera convoluções em formato variável\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "class CFG:\n",
    "    TRAIN_PATH   = \"/kaggle/input/aslamerican-sign-language-aplhabet-dataset/ASL_Alphabet_Dataset/asl_alphabet_train\"\n",
    "    IMG_SIZE     = 224\n",
    "    BATCH_SIZE   = 64\n",
    "    EPOCHS       = 20\n",
    "    LR           = 3e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    VAL_RATIO    = 0.2\n",
    "    SEQ_LEN      = 5\n",
    "    DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(CFG.IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMG_SIZE,CFG.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# 3. Dataset + Split\n",
    "full_ds = datasets.ImageFolder(CFG.TRAIN_PATH, transform=train_transform)\n",
    "val_size = int(len(full_ds) * CFG.VAL_RATIO)\n",
    "train_size = len(full_ds) - val_size\n",
    "train_ds, val_ds = random_split(full_ds, [train_size, val_size])\n",
    "# Ajusta transform do val_ds\n",
    "val_ds.dataset.transform = val_transform\n",
    "\n",
    "# 4. DataLoaders com múltiplos workers e pin_memory\n",
    "loader_kwargs = dict(batch_size=CFG.BATCH_SIZE,\n",
    "                     num_workers=os.cpu_count(),\n",
    "                     pin_memory=True)\n",
    "train_loader = DataLoader(train_ds, shuffle=True, **loader_kwargs)\n",
    "val_loader   = DataLoader(val_ds, shuffle=False, **loader_kwargs)\n",
    "\n",
    "# 5. CNN com MobileNetV3\n",
    "class ASLNet(nn.Module):\n",
    "    def __init__(self, num_classes=len(full_ds.classes)):\n",
    "        super().__init__()\n",
    "        self.backbone = mobilenet_v3_small(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc = nn.Linear(576, num_classes)\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return self.fc(feat)\n",
    "\n",
    "model = ASLNet().to(CFG.DEVICE)\n",
    "\n",
    "# 6. Mixed Precision & Otimização de Treino\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.LR, weight_decay=CFG.WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# 7. Suavização Temporal para Inferência\n",
    "class TemporalSmoother:\n",
    "    def __init__(self, seq_len):\n",
    "        self.queue = deque(maxlen=seq_len)\n",
    "    def smooth(self, preds):\n",
    "        self.queue.append(preds.detach().cpu().float())\n",
    "        stacked = torch.stack(list(self.queue), dim=0)\n",
    "        return stacked.mean(dim=0)\n",
    "\n",
    "smoother = TemporalSmoother(CFG.SEQ_LEN)\n",
    "\n",
    "# 8. Funções de Treino, Avaliação e Loop\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(CFG.DEVICE), labels.to(CFG.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        correct    += (outputs.argmax(1)==labels).sum().item()\n",
    "    return total_loss/len(loader), correct/len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(CFG.DEVICE), labels.to(CFG.DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    acc  = np.mean(np.array(all_preds)==np.array(all_labels))\n",
    "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    rec  = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1   = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    return {'loss': total_loss/len(loader), 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(1, CFG.EPOCHS+1):\n",
    "    tr_loss, tr_acc = train_epoch(train_loader)\n",
    "    metrics = eval_epoch(val_loader)\n",
    "    print(f\"Epoch {epoch}/{CFG.EPOCHS} — Train loss {tr_loss:.4f}, acc {tr_acc:.4f} | Val loss {metrics['loss']:.4f}, acc {metrics['accuracy']:.4f}\")\n",
    "    if metrics['accuracy'] > best_val_acc:\n",
    "        best_val_acc = metrics['accuracy']\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# 9. Inferência com Suavização (exemplo de uso)\n",
    "# supondo 'frames' seja iterable de batches de frames do vídeo\n",
    "# smoother = TemporalSmoother(CFG.SEQ_LEN)\n",
    "# for imgs in frames:\n",
    "#     imgs = imgs.to(CFG.DEVICE)\n",
    "#     with torch.no_grad():\n",
    "#         preds = torch.softmax(model(imgs), dim=1)\n",
    "#     smooth = smoother.smooth(preds)\n",
    "#     decisão = smooth.argmax(dim=1)\n",
    "\n",
    "# 10. Exportação JIT para C++\n",
    "scripted = torch.jit.script(model)\n",
    "scripted.save('asl_model_jit.pt')\n",
    "print('Modelo JIT salvo em asl_model_jit.pt')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
